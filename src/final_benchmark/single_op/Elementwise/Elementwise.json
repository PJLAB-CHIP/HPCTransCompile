[
    {
        "op_name": "rsqrt",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 3520) + (i1 * 320)) + (i2 * 20)) + i3)] = (1.000000e+00f / sqrtf(data[((((i0 * 3520) + (i1 * 320)) + (i2 * 20)) + i3)]));\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = (1.000000e+00f / sqrtf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 11, 16, 20), \"float32\"), compute: T.Buffer((15, 11, 16, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(15):\n            for i1, i2, i3 in T.grid(11, 16, 20):\n                cse_var_1: T.int32 = i0 * 3520 + i1 * 320 + i2 * 20 + i3\n                compute_1 = T.Buffer((52800,), data=compute.data)\n                data_1 = T.Buffer((52800,), data=data.data)\n                compute_1[cse_var_1] = T.rsqrt(data_1[cse_var_1])",
        "op_args": [
            15,
            11,
            16,
            20
        ],
        "input_shape": "[[15, 11, 16, 20]]",
        "output_shape": "[[15, 11, 16, 20]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 640) + (i1 * 64)) + (i2 * 40)) + i3)] = (1.000000e+00f / sqrtf(data[((((i0 * 640) + (i1 * 64)) + (i2 * 40)) + i3)]));\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 4800; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (1.000000e+00f / sqrtf(data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 4800; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (1.000000e+00f / sqrtf(data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}"
    },
    {
        "op_name": "sinh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)] = sinhf(data[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(34) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))] = sinhf(data[((((int)blockIdx.x) * 34) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 7, 14, 17), \"float32\"), compute: T.Buffer((13, 7, 14, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(7, 14, 17):\n                cse_var_1: T.int32 = i0 * 1666 + i1 * 238 + i2 * 17 + i3\n                compute_1 = T.Buffer((21658,), data=compute.data)\n                data_1 = T.Buffer((21658,), data=data.data)\n                compute_1[cse_var_1] = T.sinh(data_1[cse_var_1])",
        "op_args": [
            13,
            7,
            14,
            17
        ],
        "input_shape": "[[13, 7, 14, 17]]",
        "output_shape": "[[13, 7, 14, 17]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      for (int32_t i2 = 0; i2 < 14; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)] = sinhf(data[((((i0 * 1666) + (i1 * 238)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 15776; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1484; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "cosh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5814; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(48) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 6)) < 969) {\n    compute[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))] = coshf(data[((((int)blockIdx.x) * 48) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 6, 17, 19), \"float32\"), compute: T.Buffer((3, 6, 17, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(5814):\n            compute_1 = T.Buffer((5814,), data=compute.data)\n            data_1 = T.Buffer((5814,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cosh(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            3,
            6,
            17,
            19
        ],
        "input_shape": "[[3, 6, 17, 19]]",
        "output_shape": "[[3, 6, 17, 19]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 17; ++i2) {\n        for (int32_t i3 = 0; i3 < 19; ++i3) {\n          compute[((((i0 * 2108) + (i1 * 351)) + (i2 * 19)) + i3)] = coshf(data[((((i0 * 2108) + (i1 * 351)) + (i2 * 19)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 18696; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 6552; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = coshf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "sin",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2048; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))] = __sinf(data[((((int)blockIdx.x) * 4) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 16, 4), \"float32\"), compute: T.Buffer((16, 2, 16, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2048):\n            compute_1 = T.Buffer((2048,), data=compute.data)\n            data_1 = T.Buffer((2048,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.sin(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            16,
            2,
            16,
            4
        ],
        "input_shape": "[[16, 2, 16, 4]]",
        "output_shape": "[[16, 2, 16, 4]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 16; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 16; ++i2) {\n        for (int32_t i3 = 0; i3 < 4; ++i3) {\n          compute[((((i0 * 128) + (i1 * 64)) + (i2 * 4)) + i3)] = sinf(data[((((i0 * 128) + (i1 * 64)) + (i2 * 4)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 256; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2048; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = sinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "abs",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 48; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 12; ++i3) {\n        compute[(((i0_i1_fused * 48) + (i2 * 12)) + i3)] = fabsf(data[(((i0_i1_fused * 48) + (i2 * 12)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(64) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = fabsf(data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 3, 4, 12), \"float32\"), compute: T.Buffer((16, 3, 4, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(48):\n            for i2, i3 in T.grid(4, 12):\n                cse_var_1: T.int32 = i0_i1_fused * 48 + i2 * 12 + i3\n                compute_1 = T.Buffer((2304,), data=compute.data)\n                data_1 = T.Buffer((2304,), data=data.data)\n                compute_1[cse_var_1] = T.fabs(data_1[cse_var_1])",
        "op_args": [
            16,
            3,
            4,
            12
        ],
        "input_shape": "[[16, 3, 4, 12]]",
        "output_shape": "[[16, 3, 4, 12]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 16; ++i0) {\n    for (int32_t i1 = 0; i1 < 3; ++i1) {\n      for (int32_t i2 = 0; i2 < 4; ++i2) {\n        for (int32_t i3 = 0; i3 < 12; ++i3) {\n          compute[((((i0 * 144) + (i1 * 48)) + (i2 * 12)) + i3)] = fabsf(data[((((i0 * 144) + (i1 * 48)) + (i2 * 12)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 768; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = fabsf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1344; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = fabsf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "cos",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3094; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = cosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = __cosf(data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 2, 13, 7), \"float32\"), compute: T.Buffer((17, 2, 13, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(3094):\n            compute_1 = T.Buffer((3094,), data=compute.data)\n            data_1 = T.Buffer((3094,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.cos(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            17,
            2,
            13,
            7
        ],
        "input_shape": "[[17, 2, 13, 7]]",
        "output_shape": "[[17, 2, 13, 7]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i1 = 0; i1 < 2; ++i1) {\n      for (int32_t i2 = 0; i2 < 13; ++i2) {\n        for (int32_t i3 = 0; i3 < 7; ++i3) {\n          compute[((((i0 * 182) + (i1 * 91)) + (i2 * 7)) + i3)] = cosf(data[((((i0 * 182) + (i1 * 91)) + (i2 * 7)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "# C code\ndefault_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3094; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = cosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5482; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = cosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "atan",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1428; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3_s = 0; i3_s < 9; ++i3_s) {\n      compute[((i0_i1_fused_i2_fused * 9) + i3_s)] = atanf(data[((i0_i1_fused_i2_fused * 9) + i3_s)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = atanf(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 12, 7, 9), \"float32\"), compute: T.Buffer((17, 12, 7, 9), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(1428):\n            for i3_s in range(9):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 9 + i3_s\n                compute_1 = T.Buffer((12852,), data=compute.data)\n                data_1 = T.Buffer((12852,), data=data.data)\n                compute_1[cse_var_1] = T.atan(data_1[cse_var_1])",
        "op_args": [
            17,
            12,
            7,
            9
        ],
        "input_shape": "[[17, 12, 7, 9]]",
        "output_shape": "[[17, 12, 7, 9]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i1 = 0; i1 < 12; ++i1) {\n      for (int32_t i2 = 0; i2 < 7; ++i2) {\n        for (int32_t i3 = 0; i3 < 9; ++i3) {\n          compute[((((i0 * 756) + (i1 * 63)) + (i2 * 9)) + i3)] = atanf(data[((((i0 * 756) + (i1 * 63)) + (i2 * 9)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "# C code\ndefault_function_kernel(compute, data)\n\n# C code\ndef default_function_kernel(compute, data):\n    # compute_1 = atan(data)\n    compute_1 = np.arctan(data)\n    # compute = data + compute_1\n    compute[:] = data + compute_1\n\n\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1684; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = atanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "add",
        "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 20; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 10; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 9; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n          T_add[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] = (data[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)] + data_1[((((ax0 * 1620) + (ax1 * 162)) + (ax2 * 18)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(50) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))] + data_1[((((int)blockIdx.x) * 50) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((20, 10, 9, 18), \"float32\"), data_1: T.Buffer((20, 10, 9, 18), \"float32\"), T_add: T.Buffer((20, 10, 9, 18), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(20):\n            for ax1, ax2, ax3 in T.grid(10, 9, 18):\n                cse_var_1: T.int32 = ax0 * 1620 + ax1 * 162 + ax2 * 18 + ax3\n                T_add_1 = T.Buffer((32400,), data=T_add.data)\n                data_2 = T.Buffer((32400,), data=data.data)\n                data_3 = T.Buffer((32400,), data=data_1.data)\n                T_add_1[cse_var_1] = data_2[cse_var_1] + data_3[cse_var_1]",
        "op_args": [
            20,
            10,
            9,
            18
        ],
        "input_shape": "[[20, 10, 9, 18], [20, 10, 9, 18]]",
        "output_shape": "[[20, 10, 9, 18]]",
        "deepseek_c": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  for (int k0 = 0; k0 < 20; ++k0) {\n    for (int k1 = 0; k1 < 10; ++k1) {\n      for (int k2 = 0; k2 < 9; ++k2) {\n        for (int k3 = 0; k3 < 18; ++k3) {\n          T_add[((((k0 * 1620) + (k1 * 162)) + (k2 * 18)) + k3)] = (data[((((k0 * 1620) + (k1 * 162)) + (k2 * 18)) + k3)] + data_1[((((k0 * 1620) + (k1 * 162)) + (k2 * 18)) + k3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1800; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 18) + ax3)] = (data[((ax0_ax1_fused_ax2_fused * 18) + ax3)] + data_1[((ax0_ax1_fused_ax2_fused * 18) + ax3)]);\n    }\n  }\n}",
        "codellama_c": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 1800; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 18; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 18) + ax3)] = (data[((ax0_ax1_fused_ax2_fused * 18) + ax3)] + data_1[((ax0_ax1_fused_ax2_fused * 18) + ax3)]);\n    }\n  }\n}"
    },
    {
        "op_name": "acos",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1496; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(17) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))] = acosf(data[((((int)blockIdx.x) * 17) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 17, 1, 11), \"float32\"), compute: T.Buffer((8, 17, 1, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(1496):\n            compute_1 = T.Buffer((1496,), data=compute.data)\n            data_1 = T.Buffer((1496,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.acos(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            8,
            17,
            1,
            11
        ],
        "input_shape": "[[8, 17, 1, 11]]",
        "output_shape": "[[8, 17, 1, 11]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 8; ++i0) {\n    for (int32_t i1 = 0; i1 < 17; ++i1) {\n      for (int32_t i2 = 0; i2 < 1; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 187) + (i1 * 11)) + (i2 * 11)) + i3)] = acosf(data[((((i0 * 187) + (i1 * 11)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1496; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1368; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = acosf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "asin",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3_s = 0; i3_s < 7; ++i3_s) {\n          compute[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)] = asinf(data[((((i0 * 847) + (i1 * 77)) + (i2 * 7)) + i3_s)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 32) + ((int)threadIdx.x)) < 7623) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = asinf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 11, 11, 7), \"float32\"), compute: T.Buffer((9, 11, 11, 7), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(9):\n            for i1, i2, i3_s in T.grid(11, 11, 7):\n                cse_var_1: T.int32 = i0 * 847 + i1 * 77 + i2 * 7 + i3_s\n                compute_1 = T.Buffer((7623,), data=compute.data)\n                data_1 = T.Buffer((7623,), data=data.data)\n                compute_1[cse_var_1] = T.asin(data_1[cse_var_1])",
        "op_args": [
            9,
            11,
            11,
            7
        ],
        "input_shape": "[[9, 11, 11, 7]]",
        "output_shape": "[[9, 11, 11, 7]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 9; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 7; ++i3) {\n          compute[((((i0 * 770) + (i1 * 70)) + (i2 * 7)) + i3)] = asinf(data[((((i0 * 770) + (i1 * 70)) + (i2 * 7)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 7623; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = asinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 7623; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = asinf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "asinh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 240; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 19; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 19) + i3)] = asinhf(data[((i0_i1_fused_i2_fused * 19) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = asinhf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 4, 15, 19), \"float32\"), compute: T.Buffer((4, 4, 15, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(240):\n            for i3 in range(19):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 19 + i3\n                compute_1 = T.Buffer((4560,), data=compute.data)\n                data_1 = T.Buffer((4560,), data=data.data)\n                compute_1[cse_var_1] = T.asinh(data_1[cse_var_1])",
        "op_args": [
            4,
            4,
            15,
            19
        ],
        "input_shape": "[[4, 4, 15, 19]]",
        "output_shape": "[[4, 4, 15, 19]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 4; ++i1) {\n      for (int32_t i2 = 0; i2 < 15; ++i2) {\n        for (int32_t i3 = 0; i3 < 19; ++i3) {\n          compute[((((i0 * 6840) + (i1 * 1680)) + (i2 * 112)) + i3)] = asinhf(data[((((i0 * 6840) + (i1 * 1680)) + (i2 * 112)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1216; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = asinhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1560; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = asinhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "atanh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)] = atanhf(data[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(33) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))] = atanhf(data[((((int)blockIdx.x) * 33) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 9, 3, 11), \"float32\"), compute: T.Buffer((18, 9, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(18):\n            for i1, i2, i3 in T.grid(9, 3, 11):\n                cse_var_1: T.int32 = i0 * 297 + i1 * 33 + i2 * 11 + i3\n                compute_1 = T.Buffer((5346,), data=compute.data)\n                data_1 = T.Buffer((5346,), data=data.data)\n                compute_1[cse_var_1] = T.atanh(data_1[cse_var_1])",
        "op_args": [
            18,
            9,
            3,
            11
        ],
        "input_shape": "[[18, 9, 3, 11]]",
        "output_shape": "[[18, 9, 3, 11]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 18; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)] = atanhf(data[((((i0 * 297) + (i1 * 33)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5346; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = atanhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 4054; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = atanhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "ceil",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 88; ++i0_i1_fused) {\n    for (int32_t i3 = 0; i3 < 17; ++i3) {\n      compute[((i0_i1_fused * 17) + i3)] = ceilf(data[((i0_i1_fused * 17) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 187) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ceilf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((8, 11, 1, 17), \"float32\"), compute: T.Buffer((8, 11, 1, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(88):\n            for i3 in range(17):\n                cse_var_1: T.int32 = i0_i1_fused * 17 + i3\n                compute_1 = T.Buffer((1496,), data=compute.data)\n                data_1 = T.Buffer((1496,), data=data.data)\n                compute_1[cse_var_1] = T.ceil(data_1[cse_var_1])",
        "op_args": [
            8,
            11,
            1,
            17
        ],
        "input_shape": "[[8, 11, 1, 17]]",
        "output_shape": "[[8, 11, 1, 17]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 8; ++i0) {\n    for (int32_t i1 = 0; i1 < 11; ++i1) {\n      for (int32_t i2 = 0; i2 < 1; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 176) + (i1 * 16)) + (i2 * 17)) + i3)] = ceilf(data[((((i0 * 176) + (i1 * 16)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1496; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ceilf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1368; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ceilf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "erf",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 312; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(2) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))] = erff(data[((((int)blockIdx.x) * 2) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 1, 4), \"float32\"), compute: T.Buffer((13, 6, 1, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(312):\n            compute_1 = T.Buffer((312,), data=compute.data)\n            data_1 = T.Buffer((312,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.erf(data_1[i0_i1_fused_i2_fused_i3_fused])",
        "op_args": [
            13,
            6,
            1,
            4
        ],
        "input_shape": "[[13, 6, 1, 4]]",
        "output_shape": "[[13, 6, 1, 4]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i3 = 0; i3 < 4; ++i3) {\n        compute[(((i0 * 24) + (i1 * 4)) + i3)] = erff(data[(((i0 * 24) + (i1 * 4)) + i3)]);\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 312; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 504; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = erff(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "exp",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 19; ++i1) {\n    for (int32_t i2 = 0; i2 < 4; ++i2) {\n      for (int32_t i3 = 0; i3 < 10; ++i3) {\n        compute[(((i1 * 40) + (i2 * 10)) + i3)] = expf(data[(((i1 * 40) + (i2 * 10)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(20) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))] = __expf(data[((((int)blockIdx.x) * 20) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 19, 4, 10), \"float32\"), compute: T.Buffer((1, 19, 4, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(19, 4, 10):\n            cse_var_1: T.int32 = i1 * 40 + i2 * 10 + i3\n            compute_1 = T.Buffer((760,), data=compute.data)\n            data_1 = T.Buffer((760,), data=data.data)\n            compute_1[cse_var_1] = T.exp(data_1[cse_var_1])",
        "op_args": [
            1,
            19,
            4,
            10
        ],
        "input_shape": "[[1, 19, 4, 10]]",
        "output_shape": "[[1, 19, 4, 10]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 1; ++i0) {\n    for (int32_t i1 = 0; i1 < 19; ++i1) {\n      for (int32_t i2 = 0; i2 < 4; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 760) + (i1 * 40)) + (i2 * 10)) + i3)] = expf(data[((((i0 * 760) + (i1 * 40)) + (i2 * 10)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 760; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = expf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 760; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = expf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "fast_erf",
        "c_code": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 648; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 6; ++ax3) {\n      T_fast_erf[((ax0_ax1_fused_ax2_fused * 6) + ax3)] = ((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f) * max(min(data[((ax0_ax1_fused_ax2_fused * 6) + ax3)], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_erf, float* __restrict__ data) {\n  T_fast_erf[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f) * max(min(data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 12, 6, 6), \"float32\"), T_fast_erf: T.Buffer((9, 12, 6, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(648):\n            for ax3 in range(6):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 6 + ax3\n                T_fast_erf_1 = T.Buffer((3888,), data=T_fast_erf.data)\n                data_1 = T.Buffer((3888,), data=data.data)\n                T_fast_erf_1[cse_var_1] = T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-2.7261423674040941e-10) + T.float32(2.7706814620387377e-08)) + T.float32(-2.101023937939317e-06)) + T.float32(-5.6925062381196767e-05)) + T.float32(-0.00073499063728377223)) + T.float32(-0.0029545999132096767)) + T.float32(-0.016096033155918121)) / (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * (T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.max(T.min(data_1[cse_var_1], T.float32(4)), T.float32(-4)) * T.float32(-1.4566071513399947e-05) + T.float32(-0.00021337404905352741)) + T.float32(-0.001682827016338706)) + T.float32(-0.0073733292520046234)) + T.float32(-0.014264739118516445))",
        "op_args": [
            9,
            12,
            6,
            6
        ],
        "input_shape": "[[9, 12, 6, 6]]",
        "output_shape": "[[9, 12, 6, 6]]",
        "deepseek_c": "void default_function_kernel(float* T_fast_erf, float* data) {\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3888; ++i0_i1_fused_i2_fused_i3_fused) {\n    T_fast_erf[i0_i1_fused_i2_fused_i3_fused] = ((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[i0_i1_fused_i2_fused_i3_fused], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n  }\n}",
        "starcoder_c": "#include <math.h>\nvoid default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 3888; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_fast_erf[ax0_ax1_fused_ax2_fused_ax3_fused] = ((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((fmaxf(fminf(data[ax0_ax1_fused_ax2_fused_ax3_f",
        "codellama_c": "void default_function_kernel(float* T_fast_erf, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 576; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_fast_erf[ax0_ax1_fused_ax2_fused_ax3_fused] = ((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * -2.726142e-10f) + 2.770681e-08f)) + -2.101024e-06f)) + -5.692506e-05f)) + -7.349906e-04f)) + -2.954600e-03f)) + -1.609603e-02f)) / (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * (((max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f) * max(min(data[ax0_ax1_fused_ax2_fused_ax3_fused], 4.000000e+00f), -4.000000e+00f)) * -1.456607e-05f) + -2.133740e-04f)) + -1.682827e-03f)) + -7.373329e-03f)) + -1.426474e-02f));\n  }\n}"
    },
    {
        "op_name": "fast_exp",
        "c_code": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0 = 0; ax0 < 15; ++ax0) {\n    for (int32_t ax1 = 0; ax1 < 19; ++ax1) {\n      for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n        for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n            int32_t v_ = ((int32_t)(floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((ax0 * 608) + (ax1 * 32)) + (ax2 * 16)) + ax3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ T_fast_exp, float* __restrict__ data) {\n    int v_ = ((int)(floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n  T_fast_exp[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 19, 2, 16), \"float32\"), T_fast_exp: T.Buffer((15, 19, 2, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0 in T.parallel(15):\n            for ax1, ax2, ax3 in T.grid(19, 2, 16):\n                cse_var_1: T.int32 = ax0 * 608 + ax1 * 32 + ax2 * 16 + ax3\n                T_fast_exp_1 = T.Buffer((9120,), data=T_fast_exp.data)\n                data_1 = T.Buffer((9120,), data=data.data)\n                T_fast_exp_1[cse_var_1] = T.max(T.reinterpret(\"float32\", T.shift_left(T.Cast(\"int32\", T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) + T.float32(127)), 23)) * ((((((T.float32(0.00019875691214110702) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.0013981999363750219)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.008333452045917511)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.041665796190500259)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.1666666567325592)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(0.5)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) * (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + (T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) - T.floor(T.max(T.min(data_1[cse_var_1], T.float32(88.376266479492188)), T.float32(-88.376258850097656)) * T.float32(1.4426950216293335) + T.float32(0.5)) * T.float32(0.69314718246459961)) + T.float32(1)), data_1[cse_var_1])",
        "op_args": [
            15,
            19,
            2,
            16
        ],
        "input_shape": "[[15, 19, 2, 16]]",
        "output_shape": "[[15, 19, 2, 16]]",
        "deepseek_c": "void default_function_kernel(float* T_fast_exp, float* data) {\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 19; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        for (int32_t i3 = 0; i3 < 16; ++i3) {\n          int32_t v_ = ((int32_t)(floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n          T_fast_exp[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((((i0 * 192) + (i1 * 96)) + (i2 * 48)) + (i3 * 3))]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 570; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      int32_t v_ = ((int32_t)(floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) + 1.270000e+02f)) << 23;\n      T_fast_exp[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = max(((*(float *)(&(v_))) * ((((((((((((((1.987569e-04f * (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((ax0_ax1_fused_ax2_fused / 2) * 16 + ax3)]);\n    }\n  }\n}",
        "codellama_c": "void default_function_kernel(float* T_fast_exp, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 720; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      T_fast_exp[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = max(((data[((ax0_ax1_fused_ax2_fused * 16) + ax3)] * ((((((((((((((1.987569e-04f * (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.398200e-03f) * (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 8.333452e-03f) * (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 4.166580e-02f) * (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.666667e-01f) * (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 5.000000e-01f) * (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) * (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + (max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) - (floorf(((max(min(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)], 8.837627e+01f), -8.837626e+01f) * 1.442695e+00f) + 5.000000e-01f)) * 6.931472e-01f))) + 1.000000e+00f)), data[((ax0_ax1_fused_ax2_fused * 16) + ax3)]);\n    }\n  }\n}"
    },
    {
        "op_name": "fast_tanh",
        "c_code": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused = 0; ax0_ax1_fused < 252; ++ax0_ax1_fused) {\n    for (int32_t ax2 = 0; ax2 < 2; ++ax2) {\n      for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n        T_fast_tanh[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[(((ax0_ax1_fused * 24) + (ax2 * 12)) + ax3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(18) default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  T_fast_tanh[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((int)blockIdx.x) * 18) + ((int)threadIdx.x))]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((18, 14, 2, 12), \"float32\"), T_fast_tanh: T.Buffer((18, 14, 2, 12), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused in T.parallel(252):\n            for ax2, ax3 in T.grid(2, 12):\n                cse_var_1: T.int32 = ax0_ax1_fused * 24 + ax2 * 12 + ax3\n                T_fast_tanh_1 = T.Buffer((6048,), data=T_fast_tanh.data)\n                data_1 = T.Buffer((6048,), data=data.data)\n                T_fast_tanh_1[cse_var_1] = T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(-2.76076847742355e-16) + T.float32(2.0001879048247699e-13)) + T.float32(-8.60467152213735e-11)) + T.float32(5.1222970903711401e-08)) + T.float32(1.4857223571797901e-05)) + T.float32(0.00063726192887543596)) + T.float32(0.0048935245589178597)) / (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * (T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.max(T.float32(-9), T.min(T.float32(9), data_1[cse_var_1])) * T.float32(1.1982583946670199e-06) + T.float32(0.000118534705686654)) + T.float32(0.0022684346324390002)) + T.float32(0.0048935251855438504))",
        "op_args": [
            18,
            14,
            2,
            12
        ],
        "input_shape": "[[18, 14, 2, 12]]",
        "output_shape": "[[18, 14, 2, 12]]",
        "deepseek_c": "void default_function_kernel(float* __restrict__ T_fast_tanh, float* __restrict__ data) {\n  for (size_t k0 = 0; k0 < 18; ++k0) {\n    for (size_t k1 = 0; k1 < 14; ++k1) {\n      for (size_t k2 = 0; k2 < 2; ++k2) {\n        for (size_t k3 = 0; k3 < 12; ++k3) {\n          T_fast_tanh[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((((k0 * 336) + (k1 * 24)) + (k2 * 12)) + k3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "#include <math.h>\n#include <stdlib.h>\nvoid default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 504; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n      T_fast_tanh[((ax0_ax1_fused_ax2_fused * 12) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax",
        "codellama_c": "void default_function_kernel(float* T_fast_tanh, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 504; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 12; ++ax3) {\n      T_fast_tanh[((ax0_ax1_fused_ax2_fused * 12) + ax3)] = ((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * -2.760768e-16f) + 2.000188e-13f)) + -8.604672e-11f)) + 5.122297e-08f)) + 1.485722e-05f)) + 6.372619e-04f)) + 4.893525e-03f)) / (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * (((max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)])) * max(-9.000000e+00f, min(9.000000e+00f, data[((ax0_ax1_fused_ax2_fused * 12) + ax3)]))) * 1.198258e-06f) + 1.185347e-04f)) + 2.268435e-03f)) + 4.893525e-03f));\n    }\n  }\n}"
    },
    {
        "op_name": "floor",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 594; ++i0_i1_fused_i2_fused) {\n    for (int32_t i3 = 0; i3 < 10; ++i3) {\n      compute[((i0_i1_fused_i2_fused * 10) + i3)] = floorf(data[((i0_i1_fused_i2_fused * 10) + i3)]);\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(15) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))] = floorf(data[((((int)blockIdx.x) * 15) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 11, 10), \"float32\"), compute: T.Buffer((3, 18, 11, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused in T.parallel(594):\n            for i3 in range(10):\n                cse_var_1: T.int32 = i0_i1_fused_i2_fused * 10 + i3\n                compute_1 = T.Buffer((5940,), data=compute.data)\n                data_1 = T.Buffer((5940,), data=data.data)\n                compute_1[cse_var_1] = T.floor(data_1[cse_var_1])",
        "op_args": [
            3,
            18,
            11,
            10
        ],
        "input_shape": "[[3, 18, 11, 10]]",
        "output_shape": "[[3, 18, 11, 10]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 1980) + (i1 * 110)) + (i2 * 10)) + i3)] = floorf(data[((((i0 * 1980) + (i1 * 110)) + (i2 * 10)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5940; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = floorf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 5580; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = floorf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "isnan",
        "c_code": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 112; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 19; ++i2) {\n      for (int32_t i3_s = 0; i3_s < 5; ++i3_s) {\n        compute[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] = ((int8_t)(data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)] != data[(((i0_i1_fused * 95) + (i2 * 5)) + i3_s)]));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(signed char* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 665) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = ((signed char)(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] != data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 8, 19, 5), \"float32\"), compute: T.Buffer((14, 8, 19, 5), \"bool\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(112):\n            for i2, i3_s in T.grid(19, 5):\n                cse_var_1: T.int32 = i0_i1_fused * 95 + i2 * 5 + i3_s\n                compute_1 = T.Buffer((10640,), \"int8\", data=compute.data)\n                data_1 = T.Buffer((10640,), data=data.data)\n                compute_1[cse_var_1] = T.Cast(\"int8\", T.isnan(data_1[cse_var_1]))",
        "op_args": [
            14,
            8,
            19,
            5
        ],
        "input_shape": "[[14, 8, 19, 5]]",
        "output_shape": "[[14, 8, 19, 5]]",
        "deepseek_c": "void default_function_kernel(int8_t* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 14; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 19; ++i2) {\n        for (int32_t i3 = 0; i3 < 5; ++i3) {\n          compute[((((i0 * 760) + (i1 * 95)) + (i2 * 5)) + i3)] = ((int8_t)(data[((((i0 * 760) + (i1 * 95)) + (i2 * 5)) + i3)] != data[((((i0 * 760) + (i1 * 95)) + (i2 * 5)) + i3])));\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 10640; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((int8_t)(data[i0_i1_fused_i2_fused_i3_fused]!= data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}",
        "codellama_c": "void default_function_kernel(int8_t* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 13600; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((int8_t)(data[i0_i1_fused_i2_fused_i3_fused] != data[i0_i1_fused_i2_fused_i3_fused]));\n  }\n}"
    },
    {
        "op_name": "log",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)] = logf(data[((((i0 * 1836) + (i1 * 102)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(51) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))] = __logf(data[((((int)blockIdx.x) * 51) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 18, 6, 17), \"float32\"), compute: T.Buffer((3, 18, 6, 17), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(3):\n            for i1, i2, i3 in T.grid(18, 6, 17):\n                cse_var_1: T.int32 = i0 * 1836 + i1 * 102 + i2 * 17 + i3\n                compute_1 = T.Buffer((5508,), data=compute.data)\n                data_1 = T.Buffer((5508,), data=data.data)\n                compute_1[cse_var_1] = T.log(data_1[cse_var_1])",
        "op_args": [
            3,
            18,
            6,
            17
        ],
        "input_shape": "[[3, 18, 6, 17]]",
        "output_shape": "[[3, 18, 6, 17]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 18; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 17; ++i3) {\n          compute[((((i0 * 1824) + (i1 * 102)) + (i2 * 17)) + i3)] = logf(data[((((i0 * 1824) + (i1 * 102)) + (i2 * 17)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "# C code\ndefault_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1836; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = logf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3812; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = logf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "log10",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused = 0; i0_i1_fused < 42; ++i0_i1_fused) {\n    for (int32_t i2 = 0; i2 < 3; ++i2) {\n      for (int32_t i3 = 0; i3 < 6; ++i3) {\n        compute[(((i0_i1_fused * 18) + (i2 * 6)) + i3)] = log10f(data[(((i0_i1_fused * 18) + (i2 * 6)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(54) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))] = __log10f(data[((((int)blockIdx.x) * 54) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 6, 3, 6), \"float32\"), compute: T.Buffer((7, 6, 3, 6), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused in T.parallel(42):\n            for i2, i3 in T.grid(3, 6):\n                cse_var_1: T.int32 = i0_i1_fused * 18 + i2 * 6 + i3\n                compute_1 = T.Buffer((756,), data=compute.data)\n                data_1 = T.Buffer((756,), data=data.data)\n                compute_1[cse_var_1] = T.log10(data_1[cse_var_1])",
        "op_args": [
            7,
            6,
            3,
            6
        ],
        "input_shape": "[[7, 6, 3, 6]]",
        "output_shape": "[[7, 6, 3, 6]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 6; ++i3) {\n          compute[((((i0 * 108) + (i1 * 18)) + (i2 * 6)) + i3)] = log10f(data[((((i0 * 108) + (i1 * 18)) + (i2 * 6)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 756; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log10f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 252; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log10f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "log2",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i0 * 104) + (i1 * 13)) + i3)] = log2f(data[(((i0 * 104) + (i1 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 3)) < 143) {\n    compute[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = __log2f(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((11, 8, 1, 13), \"float32\"), compute: T.Buffer((11, 8, 1, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(11):\n            for i1, i3 in T.grid(8, 13):\n                cse_var_1: T.int32 = i0 * 104 + i1 * 13 + i3\n                compute_1 = T.Buffer((1144,), data=compute.data)\n                data_1 = T.Buffer((1144,), data=data.data)\n                compute_1[cse_var_1] = T.log2(data_1[cse_var_1])",
        "op_args": [
            11,
            8,
            1,
            13
        ],
        "input_shape": "[[11, 8, 1, 13]]",
        "output_shape": "[[11, 8, 1, 13]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 11; ++i0) {\n    for (int32_t i1 = 0; i1 < 8; ++i1) {\n      for (int32_t i2 = 0; i2 < 1; ++i2) {\n        for (int32_t i3 = 0; i3 < 13; ++i3) {\n          compute[((((i0 * 104) + (i1 * 13)) + (i2 * 13)) + i3)] = log2f(data[((((i0 * 104) + (i1 * 13)) + (i2 * 13)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1144; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log2f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 1104; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = log2f(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "leaky_relu",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2592; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * 5.000000e-01f));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(24) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 24) + ((int)threadIdx.x))] * 5.000000e-01f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((3, 12, 18, 4), \"float32\"), compute: T.Buffer((3, 12, 18, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(2592):\n            compute_1 = T.Buffer((2592,), data=compute.data)\n            data_1 = T.Buffer((2592,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * T.float32(0.5))",
        "op_args": [
            3,
            12,
            18,
            4
        ],
        "input_shape": "[[3, 12, 18, 4]]",
        "output_shape": "[[3, 12, 18, 4]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 3; ++i0) {\n    for (int32_t i1 = 0; i1 < 12; ++i1) {\n      for (int32_t i2 = 0; i2 < 18; ++i2) {\n        for (int32_t i3 = 0; i3 < 4; ++i3) {\n          compute[((((i0 * 864) + (i1 * 72)) + (i2 * 4)) + i3)] = ((0.000000e+00f < data[((((i0 * 864) + (i1 * 72)) + (i2 * 4)) + i3)]) ? data[((((i0 * 864) + (i1 * 72)) + (i2 * 4)) + i3)] : (data[((((i0 * 864) + (i1 * 72)) + (i2 * 4)) + i3)] * 5.000000e-01f));\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2592; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused])? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * 5.000000e-01f));\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 288; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * 5.000000e-01f));\n  }\n}"
    },
    {
        "op_name": "negative",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] = (data[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] * -1.000000e+00f);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(8) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] * -1.000000e+00f);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((4, 9, 6, 10), \"float32\"), compute: T.Buffer((4, 9, 6, 10), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(4):\n            for i1, i2, i3 in T.grid(9, 6, 10):\n                cse_var_1: T.int32 = i0 * 540 + i1 * 60 + i2 * 10 + i3\n                compute_1 = T.Buffer((2160,), data=compute.data)\n                data_1 = T.Buffer((2160,), data=data.data)\n                compute_1[cse_var_1] = data_1[cse_var_1] * T.float32(-1)",
        "op_args": [
            4,
            9,
            6,
            10
        ],
        "input_shape": "[[4, 9, 6, 10]]",
        "output_shape": "[[4, 9, 6, 10]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 4; ++i0) {\n    for (int32_t i1 = 0; i1 < 9; ++i1) {\n      for (int32_t i2 = 0; i2 < 6; ++i2) {\n        for (int32_t i3 = 0; i3 < 10; ++i3) {\n          compute[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] = (data[((((i0 * 540) + (i1 * 60)) + (i2 * 10)) + i3)] * -1.000000e+00f);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2160; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (data[i0_i1_fused_i2_fused_i3_fused] * -1.000000e+00f);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2880; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (data[i0_i1_fused_i2_fused_i3_fused] * -1.000000e+00f);\n  }\n}"
    },
    {
        "op_name": "round",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i2 = 0; i2 < 2; ++i2) {\n      for (int32_t i3 = 0; i3 < 11; ++i3) {\n        compute[(((i0 * 22) + (i2 * 11)) + i3)] = roundf(data[(((i0 * 22) + (i2 * 11)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(3) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  if (((((int)blockIdx.x) * 3) + ((int)threadIdx.x)) < 374) {\n    compute[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))] = roundf(data[((((int)blockIdx.x) * 3) + ((int)threadIdx.x))]);\n  }\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((17, 1, 2, 11), \"float32\"), compute: T.Buffer((17, 1, 2, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(17):\n            for i2, i3 in T.grid(2, 11):\n                cse_var_1: T.int32 = i0 * 22 + i2 * 11 + i3\n                compute_1 = T.Buffer((374,), data=compute.data)\n                data_1 = T.Buffer((374,), data=data.data)\n                compute_1[cse_var_1] = T.round(data_1[cse_var_1])",
        "op_args": [
            17,
            1,
            2,
            11
        ],
        "input_shape": "[[17, 1, 2, 11]]",
        "output_shape": "[[17, 1, 2, 11]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 17; ++i0) {\n    for (int32_t i1 = 0; i1 < 1; ++i1) {\n      for (int32_t i2 = 0; i2 < 2; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 22) + (i1 * 22)) + (i2 * 11)) + i3)] = roundf(data[((((i0 * 22) + (i1 * 22)) + (i2 * 11)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 374; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = roundf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 374; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = roundf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "sigmoid",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 7; ++i1) {\n    for (int32_t i2 = 0; i2 < 17; ++i2) {\n      for (int32_t i3 = 0; i3 < 4; ++i3) {\n        compute[(((i1 * 68) + (i2 * 4)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[(((i1 * 68) + (i2 * 4)) + i3)]))));\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(7) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))] = (1.000000e+00f / (1.000000e+00f + __expf((0.000000e+00f - data[((((int)blockIdx.x) * 7) + ((int)threadIdx.x))]))));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 7, 17, 4), \"float32\"), compute: T.Buffer((1, 7, 17, 4), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(7, 17, 4):\n            cse_var_1: T.int32 = i1 * 68 + i2 * 4 + i3\n            compute_1 = T.Buffer((476,), data=compute.data)\n            data_1 = T.Buffer((476,), data=data.data)\n            compute_1[cse_var_1] = T.sigmoid(data_1[cse_var_1])",
        "op_args": [
            1,
            7,
            17,
            4
        ],
        "input_shape": "[[1, 7, 17, 4]]",
        "output_shape": "[[1, 7, 17, 4]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 1; ++i0) {\n    for (int32_t i1 = 0; i1 < 7; ++i1) {\n      for (int32_t i2 = 0; i2 < 17; ++i2) {\n        for (int32_t i3 = 0; i3 < 4; ++i3) {\n          compute[((((i0 * 476) + (i1 * 68)) + (i2 * 4)) + i3)] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[((((i0 * 476) + (i1 * 68)) + (i2 * 4)) + i3)]))));\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 476; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[i0_i1_fused_i2_fused_i3_fused]))));\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 784; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = (1.000000e+00f / (1.000000e+00f + expf((0.000000e+00f - data[i0_i1_fused_i2_fused_i3_fused]))));\n  }\n}"
    },
    {
        "op_name": "sign",
        "c_code": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1248; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_sign[ax0_ax1_fused_ax2_fused_ax3_fused] = ((0.000000e+00f < data[ax0_ax1_fused_ax2_fused_ax3_fused]) ? 1.000000e+00f : ((data[ax0_ax1_fused_ax2_fused_ax3_fused] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(16) default_function_kernel(float* __restrict__ T_sign, float* __restrict__ data) {\n  T_sign[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))]) ? 1.000000e+00f : ((data[((((int)blockIdx.x) * 16) + ((int)threadIdx.x))] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((16, 2, 13, 3), \"float32\"), T_sign: T.Buffer((16, 2, 13, 3), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused_ax3_fused in T.parallel(1248):\n            T_sign_1 = T.Buffer((1248,), data=T_sign.data)\n            data_1 = T.Buffer((1248,), data=data.data)\n            T_sign_1[ax0_ax1_fused_ax2_fused_ax3_fused] = T.if_then_else(T.float32(0) < data_1[ax0_ax1_fused_ax2_fused_ax3_fused], T.float32(1), T.Select(data_1[ax0_ax1_fused_ax2_fused_ax3_fused] < T.float32(0), T.float32(-1), T.float32(0)))",
        "op_args": [
            16,
            2,
            13,
            3
        ],
        "input_shape": "[[16, 2, 13, 3]]",
        "output_shape": "[[16, 2, 13, 3]]",
        "deepseek_c": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_outer_outer = 0; ax0_ax1_fused_ax2_fused_outer_outer < 416; ++ax0_ax1_fused_ax2_fused_outer_outer) {\n    for (int32_t ax3 = 0; ax3 < 3; ++ax3) {\n      T_sign[((ax0_ax1_fused_ax2_fused_outer_outer * 3) + ax3)] = ((0.000000e+00f < data[((ax0_ax1_fused_ax2_fused_outer_outer * 3) + ax3)]) ? 1.000000e+00f : ((data[((ax0_ax1_fused_ax2_fused_outer_outer * 3) + ax3)] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 1248; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_sign[ax0_ax1_fused_ax2_fused_ax3_fused] = ((0.000000e+00f < data[ax0_ax1_fused_ax2_fused_ax3_fused])? 1.000000e+00f : ((data[ax0_ax1_fused_ax2_fused_ax3_fused] < 0.000000e+00f)? -1.000000e+00f : 0.000000e+00f));\n  }\n}",
        "codellama_c": "void default_function_kernel(float* T_sign, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 576; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    T_sign[ax0_ax1_fused_ax2_fused_ax3_fused] = ((0.000000e+00f < data[ax0_ax1_fused_ax2_fused_ax3_fused]) ? 1.000000e+00f : ((data[ax0_ax1_fused_ax2_fused_ax3_fused] < 0.000000e+00f) ? -1.000000e+00f : 0.000000e+00f));\n  }\n}"
    },
    {
        "op_name": "relu",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 6930; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(63) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))] = max(data[((((int)blockIdx.x) * 63) + ((int)threadIdx.x))], 0.000000e+00f);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((15, 14, 3, 11), \"float32\"), compute: T.Buffer((15, 14, 3, 11), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(6930):\n            compute_1 = T.Buffer((6930,), data=compute.data)\n            data_1 = T.Buffer((6930,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.max(data_1[i0_i1_fused_i2_fused_i3_fused], T.float32(0))",
        "op_args": [
            15,
            14,
            3,
            11
        ],
        "input_shape": "[[15, 14, 3, 11]]",
        "output_shape": "[[15, 14, 3, 11]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 15; ++i0) {\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      for (int32_t i2 = 0; i2 < 3; ++i2) {\n        for (int32_t i3 = 0; i3 < 11; ++i3) {\n          compute[((((i0 * 462) + (i1 * 33)) + (i2 * 11)) + i3)] = max(data[((((i0 * 462) + (i1 * 33)) + (i2 * 11)) + i3)], 0.000000e+00f);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 6930; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 630; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = max(data[i0_i1_fused_i2_fused_i3_fused], 0.000000e+00f);\n  }\n}"
    },
    {
        "op_name": "sqrt",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        compute[(((i0 * 180) + (i1 * 9)) + i2)] = sqrtf(data[(((i0 * 180) + (i1 * 9)) + i2)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(36) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((7, 20, 9, 1), \"float32\"), compute: T.Buffer((7, 20, 9, 1), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(7):\n            for i1, i2 in T.grid(20, 9):\n                cse_var_1: T.int32 = i0 * 180 + i1 * 9 + i2\n                compute_1 = T.Buffer((1260,), data=compute.data)\n                data_1 = T.Buffer((1260,), data=data.data)\n                compute_1[cse_var_1] = T.sqrt(data_1[cse_var_1])",
        "op_args": [
            7,
            20,
            9,
            1
        ],
        "input_shape": "[[7, 20, 9, 1]]",
        "output_shape": "[[7, 20, 9, 1]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 7; ++i0) {\n    for (int32_t i1 = 0; i1 < 20; ++i1) {\n      for (int32_t i2 = 0; i2 < 9; ++i2) {\n        for (int32_t i3 = 0; i3 < 1; ++i3) {\n          compute[((((i0 * 180) + (i1 * 9)) + (i2 * 1)) + i3)] = sqrtf(data[((((i0 * 180) + (i1 * 9)) + (i2 * 1)) + i3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  compute[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))] = sqrtf(data[((((int)blockIdx.x) * 36) + ((int)threadIdx.x))]);\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 1360; ++i0_i1_fused_i2_fused) {\n    compute[i0_i1_fused_i2_fused] = sqrtf(data[i0_i1_fused_i2_fused]);\n  }\n}"
    },
    {
        "op_name": "tan",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0 = 0; i0 < 13; ++i0) {\n    for (int32_t i1 = 0; i1 < 6; ++i1) {\n      for (int32_t i2 = 0; i2 < 11; ++i2) {\n        for (int32_t i3 = 0; i3 < 20; ++i3) {\n          compute[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)] = tanf(data[((((i0 * 1320) + (i1 * 220)) + (i2 * 20)) + i3)]);\n        }\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(55) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))] = tanf(data[((((int)blockIdx.x) * 55) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((13, 6, 11, 20), \"float32\"), compute: T.Buffer((13, 6, 11, 20), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0 in T.parallel(13):\n            for i1, i2, i3 in T.grid(6, 11, 20):\n                cse_var_1: T.int32 = i0 * 1320 + i1 * 220 + i2 * 20 + i3\n                compute_1 = T.Buffer((17160,), data=compute.data)\n                data_1 = T.Buffer((17160,), data=data.data)\n                compute_1[cse_var_1] = T.tan(data_1[cse_var_1])",
        "op_args": [
            13,
            6,
            11,
            20
        ],
        "input_shape": "[[13, 6, 11, 20]]",
        "output_shape": "[[13, 6, 11, 20]]",
        "deepseek_c": "void default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 171600; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = tanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "starcoder_c": "# C code\ndefault_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 17160; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = tanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}\n\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n</s>\n",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 10860; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = tanf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "prelu",
        "c_code": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 46512; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * Scale[(i0_i1_fused_i2_fused_i3_fused % 19)]));\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(38) default_function_kernel(float* __restrict__ Scale, float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] = ((0.000000e+00f < data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))]) ? data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] : (data[((((int)blockIdx.x) * 38) + ((int)threadIdx.x))] * Scale[(((int)threadIdx.x) % 19)]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((9, 17, 16, 19), \"float32\"), Scale: T.Buffer((19,), \"float32\"), compute: T.Buffer((9, 17, 16, 19), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i0_i1_fused_i2_fused_i3_fused in T.parallel(46512):\n            compute_1 = T.Buffer((46512,), data=compute.data)\n            data_1 = T.Buffer((46512,), data=data.data)\n            compute_1[i0_i1_fused_i2_fused_i3_fused] = T.if_then_else(T.float32(0) < data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused], data_1[i0_i1_fused_i2_fused_i3_fused] * Scale[i0_i1_fused_i2_fused_i3_fused % 19])",
        "op_args": [
            9,
            17,
            16,
            19
        ],
        "input_shape": "[[9, 17, 16, 19], [19]]",
        "output_shape": "[[9, 17, 16, 19]]",
        "deepseek_c": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_ax3_fused = 0; ax0_ax1_fused_ax2_fused_ax3_fused < 26208; ++ax0_ax1_fused_ax2_fused_ax3_fused) {\n    compute[ax0_ax1_fused_ax2_fused_ax3_fused] = ((0.000000e+00f < data[ax0_ax1_fused_ax2_fused_ax3_fused]) ? data[ax0_ax1_fused_ax2_fused_ax3_fused] : (data[ax0_ax1_fused_ax2_fused_ax3_fused] * Scale[((ax0_ax1_fused_ax2_fused_ax3_fused % 19) + 19) % 19)]));\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 2432; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused])? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * Scale[i0_i1_fused_i2_fused_i3_fused % 19]));\n  }\n}",
        "codellama_c": "void default_function_kernel(float* Scale, float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3888; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = ((0.000000e+00f < data[i0_i1_fused_i2_fused_i3_fused]) ? data[i0_i1_fused_i2_fused_i3_fused] : (data[i0_i1_fused_i2_fused_i3_fused] * Scale[(i0_i1_fused_i2_fused_i3_fused % 19)]));\n  }\n}"
    },
    {
        "op_name": "tanh",
        "c_code": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i1 = 0; i1 < 20; ++i1) {\n    for (int32_t i2 = 0; i2 < 14; ++i2) {\n      for (int32_t i3 = 0; i3 < 13; ++i3) {\n        compute[(((i1 * 182) + (i2 * 13)) + i3)] = tanhf(data[(((i1 * 182) + (i2 * 13)) + i3)]);\n      }\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(28) default_function_kernel(float* __restrict__ compute, float* __restrict__ data) {\n  compute[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))] = tanhf(data[((((int)blockIdx.x) * 28) + ((int)threadIdx.x))]);\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((1, 20, 14, 13), \"float32\"), compute: T.Buffer((1, 20, 14, 13), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for i1, i2, i3 in T.grid(20, 14, 13):\n            cse_var_1: T.int32 = i1 * 182 + i2 * 13 + i3\n            compute_1 = T.Buffer((3640,), data=compute.data)\n            data_1 = T.Buffer((3640,), data=data.data)\n            compute_1[cse_var_1] = T.tanh(data_1[cse_var_1])",
        "op_args": [
            1,
            20,
            14,
            13
        ],
        "input_shape": "[[1, 20, 14, 13]]",
        "output_shape": "[[1, 20, 14, 13]]",
        "deepseek_c": "void default_function_kernel(float* compute, float* data) {\n  for (int32_t i0 = 0; i0 < 20; ++i0) {\n    for (int32_t i1 = 0; i1 < 14; ++i1) {\n      for (int32_t i2 = 0; i2 < 13; ++i2) {\n        for (int32_t ax3 = 0; ax3 < 28; ++ax3) {\n          compute[((((i0 * 364) + (i1 * 26)) + (i2 * 13)) + ax3)] = tanhf(data[((((i0 * 364) + (i1 * 26)) + (i2 * 13)) + ax3)]);\n        }\n      }\n    }\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 3640; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = tanhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}",
        "codellama_c": "void default_function_kernel(float* compute, float* data) {\n  #pragma omp parallel for\n  for (int32_t i0_i1_fused_i2_fused_i3_fused = 0; i0_i1_fused_i2_fused_i3_fused < 4280; ++i0_i1_fused_i2_fused_i3_fused) {\n    compute[i0_i1_fused_i2_fused_i3_fused] = tanhf(data[i0_i1_fused_i2_fused_i3_fused]);\n  }\n}"
    },
    {
        "op_name": "combination_op",
        "c_code": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 392; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 16) + ax3)]));\n    }\n  }\n}\n\n",
        "cuda_code": "extern \"C\" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_add, float* __restrict__ data, float* __restrict__ data_1) {\n  T_add[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = (sqrtf(data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]) + __cosf(data_1[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]));\n}\n\n",
        "ir_code": "# from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(data: T.Buffer((14, 4, 7, 16), \"float32\"), data_1: T.Buffer((14, 4, 7, 16), \"float32\"), T_add: T.Buffer((14, 4, 7, 16), \"float32\")):\n        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n        for ax0_ax1_fused_ax2_fused in T.parallel(392):\n            for ax3 in range(16):\n                cse_var_1: T.int32 = ax0_ax1_fused_ax2_fused * 16 + ax3\n                T_add_1 = T.Buffer((6272,), data=T_add.data)\n                data_2 = T.Buffer((6272,), data=data.data)\n                data_3 = T.Buffer((6272,), data=data_1.data)\n                T_add_1[cse_var_1] = T.sqrt(data_2[cse_var_1]) + T.cos(data_3[cse_var_1])",
        "op_args": [
            14,
            4,
            7,
            16
        ],
        "input_shape": "[[14, 4, 7, 16], [14, 4, 7, 16]]",
        "output_shape": "[[14, 4, 7, 16]]",
        "deepseek_c": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused_inner_inner = 0; ax0_ax1_fused_ax2_fused_inner_inner < 392; ++ax0_ax1_fused_ax2_fused_inner_inner) {\n    T_add[ax0_ax1_fused_ax2_fused_inner_inner] = (sqrtf(data[ax0_ax1_fused_ax2_fused_inner_inner]) + cosf(data_1[ax0_ax1_fused_ax2_fused_inner_inner]));\n  }\n}",
        "starcoder_c": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 392; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 16) + ax3)]));\n    }\n  }\n}",
        "codellama_c": "void default_function_kernel(float* T_add, float* data, float* data_1) {\n  #pragma omp parallel for\n  for (int32_t ax0_ax1_fused_ax2_fused = 0; ax0_ax1_fused_ax2_fused < 576; ++ax0_ax1_fused_ax2_fused) {\n    for (int32_t ax3 = 0; ax3 < 16; ++ax3) {\n      T_add[((ax0_ax1_fused_ax2_fused * 16) + ax3)] = (sqrtf(data[((ax0_ax1_fused_ax2_fused * 16) + ax3)]) + cosf(data_1[((ax0_ax1_fused_ax2_fused * 16) + ax3)]));\n    }\n  }\n}"
    }
]