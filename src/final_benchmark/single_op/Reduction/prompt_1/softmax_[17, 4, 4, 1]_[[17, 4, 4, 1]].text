
    Task: Translate the given CUDA code to its equivalent High performace CPU C code.  
    Context: You are provided with a CUDA code snippet that needs to be translated into CPU C code. The translation should preserve the same functionality as much as possible. Focus on translating the CUDA-specific parallel constructs into the constructs supported by CPU, such as using OpenMP for parallelism. The resulting CPU C code should be complete and ready to compile. 
    Input CUDA Code: extern "C" __global__ void __launch_bounds__(32) default_function_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {
  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {
    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = -3.402823e+38f;
  }
  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 4)) < 17) {
    T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))], data[((((int)blockIdx.x) * 32) + ((int)threadIdx.x))]);
  }
}

extern "C" __global__ void __launch_bounds__(64) default_function_kernel_2(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm, float* __restrict__ data) {
  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 4)) < 17) {
    T_softmax_norm[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] = (__expf((data[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))])) / T_softmax_expsum[((((int)blockIdx.x) * 64) + ((int)threadIdx.x))]);
  }
}

extern "C" __global__ void __launch_bounds__(8) default_function_kernel_1(float* __restrict__ T_softmax_expsum, float* __restrict__ T_softmax_maxelem, float* __restrict__ data) {
  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = 0.000000e+00f;
  T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] = (T_softmax_expsum[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] + __expf((data[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))] - T_softmax_maxelem[((((int)blockIdx.x) * 8) + ((int)threadIdx.x))])));
}


    Ihe input tensor shape is [[17, 4, 4, 1]] respectively, Print only single C function implementation, end with comment '|End-of-Code|'.
    